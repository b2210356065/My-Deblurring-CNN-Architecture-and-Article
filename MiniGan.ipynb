{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4",
   "machine_shape": "hm"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import zipfile\n",
    "import os\n",
    "zip_path = \"/content/drive/MyDrive/GOPRO_Large.zip\"\n",
    "\n",
    "extract_path = \"/content/gopro_data\"\n",
    "\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_path)\n",
    "\n",
    "print(\"Veri başarıyla çıkarıldı:\", os.listdir(extract_path))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "folder_path = '/content/gopro_data'\n",
    "train_path = os.path.join(folder_path, 'train')\n",
    "test_path = os.path.join(folder_path, 'test')\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "X_train = []\n",
    "Y_train = []\n",
    "X_test = []\n",
    "Y_test = []\n",
    "\n",
    "image_size = (800 , 450)  # sabit boyut (örnek)\n",
    "\n",
    "def load_image_tensor(path):\n",
    "    img = cv2.imread(path)\n",
    "    if img is None:\n",
    "        return None\n",
    "    img = cv2.resize(img, image_size)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = img.astype(np.float32) / 255.0\n",
    "    img = np.transpose(img, (2, 0, 1))  # HWC → CHW\n",
    "    return torch.tensor(img)\n",
    "\n",
    "# Eğitim verisi: blur → sharp eşleşmesi\n",
    "for class_folder in os.listdir(train_path):\n",
    "    class_path = os.path.join(train_path, class_folder)\n",
    "    blur_path = os.path.join(class_path, 'blur')\n",
    "    sharp_path = os.path.join(class_path, 'sharp')\n",
    "\n",
    "    if os.path.isdir(blur_path) and os.path.isdir(sharp_path):\n",
    "        for image_file in os.listdir(blur_path):\n",
    "            blur_img_path = os.path.join(blur_path, image_file)\n",
    "            sharp_img_path = os.path.join(sharp_path, image_file)  # Aynı isimde olmalı\n",
    "\n",
    "            blur_tensor = load_image_tensor(blur_img_path)\n",
    "            sharp_tensor = load_image_tensor(sharp_img_path)\n",
    "\n",
    "            if blur_tensor is not None and sharp_tensor is not None:\n",
    "                X_train.append(blur_tensor)\n",
    "                Y_train.append(sharp_tensor)\n",
    "\n",
    "# Test verisi: aynı şekilde\n",
    "for class_folder in os.listdir(test_path):\n",
    "    class_path = os.path.join(test_path, class_folder)\n",
    "    blur_path = os.path.join(class_path, 'blur')\n",
    "    sharp_path = os.path.join(class_path, 'sharp')\n",
    "\n",
    "    if os.path.isdir(blur_path) and os.path.isdir(sharp_path):\n",
    "        for image_file in os.listdir(blur_path):\n",
    "            blur_img_path = os.path.join(blur_path, image_file)\n",
    "            sharp_img_path = os.path.join(sharp_path, image_file)\n",
    "\n",
    "            blur_tensor = load_image_tensor(blur_img_path)\n",
    "            sharp_tensor = load_image_tensor(sharp_img_path)\n",
    "\n",
    "            if blur_tensor is not None and sharp_tensor is not None:\n",
    "                X_test.append(blur_tensor)\n",
    "                Y_test.append(sharp_tensor)"
   ],
   "metadata": {
    "id": "421JypDE_r2q",
    "ExecuteTime": {
     "end_time": "2025-05-24T13:12:15.849269Z",
     "start_time": "2025-05-24T13:09:23.575068Z"
    }
   },
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "\n",
    "        # l1: conv(3 -> 32), bn, relu\n",
    "        self.l1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # l2: conv(32 -> 64), bn, relu\n",
    "        self.l2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # t1: input + max_pool(input)\n",
    "        self.maxpool_t1_t4 = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        # Bottleneck: 64 -> 32 (t2 öncesi)\n",
    "        self.bottleneck = nn.Conv2d(64, 32, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "        # t2 components: four convs for 32 -> 16 each (bottleneck sonrası)\n",
    "        self.t2_conv1 = nn.Conv2d(32, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.t2_conv2 = nn.Conv2d(32, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.t2_conv3 = nn.Conv2d(32, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.t2_conv4 = nn.Conv2d(32, 16, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        # t3 reductions\n",
    "        self.t3_reduce_l6 = nn.Conv2d(192, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.t3_reduce_l8_l9 = nn.Conv2d(128, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.t3_reduce_l11 = nn.Conv2d(96, 32, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        # Final conv\n",
    "        self.final_conv = nn.Conv2d(32, 3, kernel_size=3, stride=1, padding=1)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def t1(self, x):\n",
    "        max_pooled = self.maxpool_t1_t4(x)\n",
    "        return x + max_pooled\n",
    "\n",
    "    def t2(self, x):\n",
    "        x = self.bottleneck(x)  # 64 -> 32\n",
    "        c1 = self.t2_conv1(x)\n",
    "        c2 = self.t2_conv2(x)\n",
    "        c3 = self.t2_conv3(x)\n",
    "        c4 = self.t2_conv4(x)\n",
    "        return torch.cat([c1, c2, c3, c4], dim=1)  # [64, 450, 800]\n",
    "\n",
    "    def t4(self, x):\n",
    "        max_pooled = self.maxpool_t1_t4(x)\n",
    "        concat = torch.cat([x, max_pooled], dim=1)\n",
    "        return nn.functional.relu(concat)\n",
    "\n",
    "    def forward(self, x):\n",
    "        l1_out = self.l1(x)        # [32, 450, 800]\n",
    "        l2_out = self.l2(l1_out)   # [64, 450, 800]\n",
    "        l3_out = self.t1(l2_out)   # [64, 450, 800]\n",
    "        l4_out = self.t2(l3_out)   # [64, 450, 800]\n",
    "        l5_out = self.t4(l4_out)   # [128, 450, 800]\n",
    "        l6_concat = torch.cat([l5_out, l4_out], dim=1)  # [192, 450, 800]\n",
    "        l6_out = self.t3_reduce_l6(l6_concat)  # [64, 450, 800]\n",
    "        l7_out = self.t2(l6_out)   # [64, 450, 800]\n",
    "        l8_concat = torch.cat([l7_out, l3_out], dim=1)  # [128, 450, 800]\n",
    "        l8_out = self.t3_reduce_l8_l9(l8_concat)  # [64, 450, 800]\n",
    "        l9_concat = torch.cat([l8_out, l2_out], dim=1)  # [128, 450, 800]\n",
    "        l9_out = self.t3_reduce_l8_l9(l9_concat)  # [64, 450, 800]\n",
    "        l10_out = self.t2(l9_out)  # [64, 450, 800]\n",
    "        l11_concat = torch.cat([l10_out, l1_out], dim=1)  # [96, 450, 800]\n",
    "        l11_out = self.t3_reduce_l11(l11_concat)  # [32, 450, 800]\n",
    "        l12_out = self.t1(l11_out)  # [32, 450, 800]\n",
    "        final = self.final_conv(l12_out)  # [3, 450, 800]\n",
    "        output = self.tanh(final) + x  # Residual connection\n",
    "        return output\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(512, 1, kernel_size=4, stride=1, padding=0),\n",
    "            nn.Sigmoid()  # PatchGAN: her patch için 0-1 tahmini\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n"
   ],
   "metadata": {
    "id": "hRqS_tkrI-FU",
    "ExecuteTime": {
     "end_time": "2025-05-24T13:12:16.004239Z",
     "start_time": "2025-05-24T13:12:15.989624Z"
    }
   },
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader, Subset\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torchmetrics.image import StructuralSimilarityIndexMeasure\n",
    "from torchvision import transforms\n",
    "import os\n",
    "\n",
    "def calculate_psnr(img1, img2, max_val=1.0):\n",
    "    \"\"\"Calculate PSNR (Peak Signal-to-Noise Ratio) between two images.\"\"\"\n",
    "    mse = torch.mean((img1 - img2) ** 2)\n",
    "    if mse == 0:\n",
    "        return float('inf')\n",
    "    return 20 * torch.log10(max_val / torch.sqrt(mse)).item()\n",
    "\n",
    "def train_model_progressive(generator, discriminator, X_train, Y_train, batch_size=8, epochs=50, lr=5e-3, lambda_mse=1.0, lambda_ssim=0.3, lambda_adv=0.01, device=None, save_path=\"best_model.pth\"):\n",
    "    # Cihaz ayarı\n",
    "    if device is None:\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    generator = generator.to(device)\n",
    "    discriminator = discriminator.to(device)\n",
    "\n",
    "    # Optimizörler\n",
    "    optimizer_g = torch.optim.Adam(generator.parameters(), lr=lr, weight_decay=1e-4)\n",
    "    optimizer_d = torch.optim.Adam(discriminator.parameters(), lr=lr, weight_decay=1e-4)\n",
    "\n",
    "    # Öğrenme oranı scheduler\n",
    "    scheduler_g = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer_g, mode='min', factor=0.5, patience=5)\n",
    "    scheduler_d = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer_d, mode='min', factor=0.5, patience=5)\n",
    "\n",
    "    # Kayıplar\n",
    "    mse_loss = nn.MSELoss()\n",
    "    ssim = StructuralSimilarityIndexMeasure(data_range=1.0).to(device)\n",
    "    adversarial_loss = nn.BCELoss()\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(10),\n",
    "    ])\n",
    "\n",
    "    # X_train ve Y_train için aynı dönüşümleri uygula\n",
    "    X_train_aug = []\n",
    "    Y_train_aug = []\n",
    "    for x, y in zip(X_train, Y_train):\n",
    "        # Aynı rastgele dönüşümü hem x hem y için uygula\n",
    "        seed = torch.randint(0, 2**32, (1,)).item()  # Rastgele tohum\n",
    "        torch.manual_seed(seed)  # x için tohumu ayarla\n",
    "        x_aug = transform(x.clone())\n",
    "        torch.manual_seed(seed)  # y için aynı tohumu kullan\n",
    "        y_aug = transform(y.clone())\n",
    "        X_train_aug.append(x_aug)\n",
    "        Y_train_aug.append(y_aug)\n",
    "\n",
    "    # Tüm veri setini kullan\n",
    "    full_dataset = TensorDataset(torch.stack(X_train_aug), torch.stack(Y_train_aug))\n",
    "\n",
    "    # Eğitim ve doğrulama için bölme (%80 eğitim, %20 doğrulama)\n",
    "    total_size = len(full_dataset)\n",
    "    train_size = int(0.8 * total_size)\n",
    "    val_size = total_size - train_size\n",
    "    indices = np.random.permutation(total_size)\n",
    "    train_indices = indices[:train_size]\n",
    "    val_indices = indices[train_size:]\n",
    "\n",
    "    train_dataset = Subset(full_dataset, train_indices)\n",
    "    val_dataset = Subset(full_dataset, val_indices)\n",
    "\n",
    "    # DataLoader'lar\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Kayıp izleme\n",
    "    train_g_losses, val_g_losses = [], []\n",
    "    train_d_losses = []\n",
    "    train_ssim, val_ssim = [], []\n",
    "    train_psnr, val_psnr = [], []\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    patience = 10\n",
    "    patience_counter = 0\n",
    "    for epoch in range(epochs):\n",
    "        # 30 epoch’ta tam veri setine geçiş\n",
    "        if (epoch + 1) % 30 == 0:\n",
    "            optimizer_g = torch.optim.Adam(generator.parameters(), lr=lr/10, weight_decay=1e-4)\n",
    "            optimizer_d = torch.optim.Adam(discriminator.parameters(), lr=lr/10, weight_decay=1e-4)\n",
    "\n",
    "        # Eğitim aşaması\n",
    "        generator.train()\n",
    "        discriminator.train()\n",
    "        train_g_loss = 0.0\n",
    "        train_d_loss = 0.0\n",
    "        train_ssim_sum = 0.0\n",
    "        train_psnr_sum = 0.0\n",
    "        train_count = 0\n",
    "\n",
    "        for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
    "            inputs, targets = batch\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            batch_size = inputs.size(0)\n",
    "\n",
    "            # Diskriminatör Eğitimi\n",
    "            optimizer_d.zero_grad()\n",
    "            real_labels = torch.ones(batch_size, 1).to(device)\n",
    "            fake_labels = torch.zeros(batch_size, 1).to(device)\n",
    "\n",
    "            real_output = discriminator(targets).mean(dim=[2, 3])\n",
    "            d_loss_real = adversarial_loss(real_output, real_labels)\n",
    "\n",
    "            fake_images = generator(inputs)\n",
    "            fake_output = discriminator(fake_images.detach()).mean(dim=[2, 3])\n",
    "            d_loss_fake = adversarial_loss(fake_output, fake_labels)\n",
    "\n",
    "            d_loss = (d_loss_real + d_loss_fake) / 2\n",
    "            d_loss.backward()\n",
    "            optimizer_d.step()\n",
    "\n",
    "            # Jeneratör Eğitimi\n",
    "            optimizer_g.zero_grad()\n",
    "            fake_output = discriminator(fake_images).mean(dim=[2, 3])\n",
    "            g_loss_adv = adversarial_loss(fake_output, real_labels)\n",
    "\n",
    "            mse = mse_loss(fake_images, targets)\n",
    "            ssim_val = ssim(fake_images, targets)\n",
    "            g_loss = lambda_mse * mse + lambda_ssim * (1 - ssim_val) + lambda_adv * g_loss_adv\n",
    "\n",
    "            g_loss.backward()\n",
    "            optimizer_g.step()\n",
    "\n",
    "            train_g_loss += g_loss.item() * batch_size\n",
    "            train_d_loss += d_loss.item() * batch_size\n",
    "            train_ssim_sum += ssim_val.item() * batch_size\n",
    "            train_psnr_sum += calculate_psnr(fake_images, targets) * batch_size\n",
    "            train_count += batch_size\n",
    "\n",
    "        avg_train_g_loss = train_g_loss / train_count\n",
    "        avg_train_d_loss = train_d_loss / train_count\n",
    "        avg_train_ssim = train_ssim_sum / train_count\n",
    "        avg_train_psnr = train_psnr_sum / train_count\n",
    "        train_g_losses.append(avg_train_g_loss)\n",
    "        train_d_losses.append(avg_train_d_loss)\n",
    "        train_ssim.append(avg_train_ssim)\n",
    "        train_psnr.append(avg_train_psnr)\n",
    "\n",
    "        # Doğrulama aşaması\n",
    "        generator.eval()\n",
    "        discriminator.eval()\n",
    "        val_g_loss = 0.0\n",
    "        val_ssim_sum = 0.0\n",
    "        val_psnr_sum = 0.0\n",
    "        val_count = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                inputs, targets = batch\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                batch_size = inputs.size(0)\n",
    "\n",
    "                fake_images = generator(inputs)\n",
    "\n",
    "                mse = mse_loss(fake_images, targets)\n",
    "                ssim_val = ssim(fake_images, targets)\n",
    "                g_loss = lambda_mse * mse + lambda_ssim * (1 - ssim_val)\n",
    "\n",
    "                val_g_loss += g_loss.item() * batch_size\n",
    "                val_ssim_sum += ssim_val.item() * batch_size\n",
    "                val_psnr_sum += calculate_psnr(fake_images, targets) * batch_size\n",
    "                val_count += batch_size\n",
    "\n",
    "        avg_val_g_loss = val_g_loss / val_count\n",
    "        avg_val_ssim = val_ssim_sum / val_count\n",
    "        avg_val_psnr = val_psnr_sum / val_count\n",
    "        val_g_losses.append(avg_val_g_loss)\n",
    "        val_ssim.append(avg_val_ssim)\n",
    "        val_psnr.append(avg_val_psnr)\n",
    "\n",
    "        # Scheduler adımı\n",
    "        scheduler_g.step(avg_val_g_loss)\n",
    "        scheduler_d.step(avg_val_g_loss)\n",
    "\n",
    "        # İlerleme yazdırma\n",
    "        current_lr = optimizer_g.param_groups[0]['lr']\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, LR: {current_lr:.6f}\")\n",
    "        print(f\"Train G Loss: {avg_train_g_loss:.6f}, Train D Loss: {avg_train_d_loss:.6f}, Train SSIM: {avg_train_ssim:.4f}, Train PSNR: {avg_train_psnr:.2f} dB\")\n",
    "        print(f\"Val G Loss: {avg_val_g_loss:.6f}, Val SSIM: {avg_val_ssim:.4f}, Val PSNR: {avg_val_psnr:.2f} dB\")\n",
    "\n",
    "        # Checkpointing\n",
    "        if avg_val_g_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_g_loss\n",
    "            torch.save({\n",
    "                'generator_state_dict': generator.state_dict(),\n",
    "                'discriminator_state_dict': discriminator.state_dict(),\n",
    "            }, save_path)\n",
    "            print(f\"Best model saved at epoch {epoch+1} with Val G Loss: {best_val_loss:.6f}\")\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        # Erken durdurma\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "\n",
    "    return generator, discriminator, train_g_losses, val_g_losses, train_ssim, val_ssim, train_psnr, val_psnr\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "# Modelleri başlatma\n",
    "generator = NeuralNetwork().to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "\n",
    "# Eğitimi başlatma\n",
    "trained_generator, trained_discriminator, train_g_losses, val_g_losses, train_ssim, val_ssim , train_psnr , val_psnr = train_model_progressive(\n",
    "    generator=generator,\n",
    "    discriminator=discriminator,\n",
    "    X_train=X_train,\n",
    "    Y_train=Y_train,\n",
    "    batch_size=4,\n",
    "    epochs=100,\n",
    "    lr=5e-4,\n",
    "    lambda_mse=1.0,\n",
    "    lambda_ssim=0.3,\n",
    "    lambda_adv=0.01,\n",
    "    device=device,\n",
    "    save_path=\"/content/best_model.pth\"  # Colab için yol\n",
    ")\n",
    "\n",
    "# Eğitim sonuçlarını yazdırma\n",
    "print(\"Eğitim tamamlandı.\")\n",
    "print(f\"Son Train G Loss: {train_g_losses[-1]:.6f}, Son Val G Loss: {val_g_losses[-1]:.6f}\")\n",
    "print(f\"Son Train SSIM: {train_ssim[-1]:.4f}, Son Val SSIM: {val_ssim[-1]:.4f}\")\n"
   ],
   "metadata": {
    "id": "HcH1mU6DWRaf",
    "outputId": "316d639f-6d6a-4240-899a-c5983e96e10a",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "ExecuteTime": {
     "end_time": "2025-05-24T13:12:22.511275Z",
     "start_time": "2025-05-24T13:12:16.017753Z"
    }
   },
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_test_results(model_path, X_test, Y_test, num_samples=3, device=None):\n",
    "    \"\"\"\n",
    "    Load the best GAN generator model and visualize predictions on test data.\n",
    "\n",
    "    Args:\n",
    "        model_path: Path to the saved model checkpoint (e.g., '/content/best_gan_model.pth')\n",
    "        X_test: List of test input tensors [3, 450, 800]\n",
    "        Y_test: List of test target tensors [3, 450, 800]\n",
    "        num_samples: Number of samples to visualize\n",
    "        device: Device to run model ('cuda' or 'cpu')\n",
    "    \"\"\"\n",
    "    # Set device\n",
    "    if device is None:\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "    # Load generator model\n",
    "    model = NeuralNetwork()\n",
    "    try:\n",
    "        checkpoint = torch.load(model_path, map_location=device)\n",
    "        model.load_state_dict(checkpoint['generator_state_dict'])\n",
    "    except KeyError as e:\n",
    "        raise KeyError(f\"Checkpoint at {model_path} does not contain 'generator_state_dict'. Ensure the model was saved correctly.\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # Initialize SSIM metric\n",
    "    ssim = StructuralSimilarityIndexMeasure(data_range=1.0).to(device)\n",
    "\n",
    "    # Randomly select samples\n",
    "    indices = np.random.permutation(len(X_test))[:num_samples]\n",
    "    X_samples = [X_test[i] for i in indices]\n",
    "    Y_samples = [Y_test[i] for i in indices]\n",
    "\n",
    "    # Plotting\n",
    "    fig, axes = plt.subplots(num_samples, 3, figsize=(15, 5 * num_samples))\n",
    "    if num_samples == 1:\n",
    "        axes = [axes]  # Ensure axes is iterable for single sample\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(num_samples):\n",
    "            # Prepare input\n",
    "            input_img = X_samples[i].unsqueeze(0).to(device)  # [1, 3, 450, 800]\n",
    "            target_img = Y_samples[i].to(device)  # [3, 450, 800]\n",
    "\n",
    "            # Get prediction\n",
    "            output_img = model(input_img).squeeze(0)  # [3, 450, 800]\n",
    "\n",
    "            # Calculate metrics\n",
    "            input_ssim = ssim(input_img, target_img.unsqueeze(0)).item()\n",
    "            input_psnr = calculate_psnr(input_img, target_img.unsqueeze(0))\n",
    "            pred_ssim = ssim(output_img.unsqueeze(0), target_img.unsqueeze(0)).item()\n",
    "            pred_psnr = calculate_psnr(output_img.unsqueeze(0), target_img.unsqueeze(0))\n",
    "\n",
    "            # Convert tensors to numpy for plotting\n",
    "            input_np = input_img.squeeze().cpu().numpy().transpose(1, 2, 0)  # [450, 800, 3]\n",
    "            target_np = target_img.cpu().numpy().transpose(1, 2, 0)\n",
    "            output_np = output_img.cpu().numpy().transpose(1, 2, 0)\n",
    "\n",
    "            # Clip to [0, 1] for visualization\n",
    "            input_np = np.clip(input_np, 0, 1)\n",
    "            target_np = np.clip(target_np, 0, 1)\n",
    "            output_np = np.clip(output_np, 0, 1)\n",
    "\n",
    "            # Plot\n",
    "            axes[i][0].imshow(input_np)\n",
    "            axes[i][0].set_title(f\"Input (Blur)\\nSSIM: {input_ssim:.4f}, PSNR: {input_psnr:.2f} dB\")\n",
    "            axes[i][0].axis('off')\n",
    "\n",
    "            axes[i][1].imshow(target_np)\n",
    "            axes[i][1].set_title(\"Target (Sharp)\")\n",
    "            axes[i][1].axis('off')\n",
    "\n",
    "            axes[i][2].imshow(output_np)\n",
    "            axes[i][2].set_title(f\"Predicted\\nSSIM: {pred_ssim:.4f}, PSNR: {pred_psnr:.2f} dB\")\n",
    "            axes[i][2].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage with placeholder data\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Visualize\n",
    "    visualize_test_results(\n",
    "        model_path=\"/content/best_model.pth\",\n",
    "        X_test=X_test,\n",
    "        Y_test=Y_test,\n",
    "        num_samples=50,\n",
    "        device=None\n",
    "    )"
   ],
   "metadata": {
    "id": "S5oV7isjk0dp"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "Cv3V7xzQ0VVB"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
